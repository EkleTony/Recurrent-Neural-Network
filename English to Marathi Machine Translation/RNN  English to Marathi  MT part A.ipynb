{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level English to Marathi Neural Machine Translation using Encoder-Decoder Model\n",
    "\n",
    "* Recurrent Neural Networks (or more precisely LSTM/GRU) have been found to be very effective in solving complex sequence related problems given a large amount of data. They have real time applications in speech recognition, Natural Language Processing (NLP) problems, time series forecasting, etc. This blog nicely explains some of these applications.\n",
    "* Sequence to Sequence (often abbreviated to seq2seq) models are a special class of Recurrent Neural Network architectures typically used (but not restricted) to solve complex Language related problems like Machine Translation, Question Answering, creating Chat-bots, Text Summarization, etc.\n",
    "\n",
    "# Summary of the encoder:\n",
    "* We will read the input sequence (English sentence) word by word and preserve the internal states of the LSTM network generated after the last time step hk, ck (assuming the sentence has ‘k’ words). These vectors (states hk and ck) are called as the encoding of the input sequence, as they encode (summarize) the entire input in a vector form. Since we will start generating the output once we have read the entire sequence, outputs (Yi) of the Encoder at each time step are discarded.\n",
    "* Moreover you must also understand what type of vectors are Xi, hi, ci and Yi. What are their sizes (shapes) and what do they represent. If you have any confusion understanding this part, then you need to first strengthen your understanding of LSTM and language models.\n",
    "\n",
    "# Inference Algorithm:\n",
    "1.  During inference, we generate one word at a time. Thus the Decoder LSTM is called in a loop, every time processing only one time step.\n",
    "2. The initial states of the decoder are set to the final states of the encoder.\n",
    "3. The initial input to the decoder is always the START_ token.\n",
    "4. At each time step, we preserve the states of the decoder and set them as initial states for the next time step.\n",
    "5. At each time step, the predicted output is fed as input in the next time step.\n",
    "6. We break the loop when the decoder predicts the END_ token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pd.read_table('mar.txt', names=['eng', 'mar', 'code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>जा.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>पळ!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>धाव!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>पळा!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>धावा!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40746</th>\n",
       "      <td>Just saying you don't like fish because of the...</td>\n",
       "      <td>हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40747</th>\n",
       "      <td>The Japanese Parliament today officially elect...</td>\n",
       "      <td>आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40748</th>\n",
       "      <td>Tom tried to sell his old VCR instead of throw...</td>\n",
       "      <td>टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40749</th>\n",
       "      <td>You can't view Flash content on an iPad. Howev...</td>\n",
       "      <td>आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40750</th>\n",
       "      <td>In 1969, Roger Miller recorded a song called \"...</td>\n",
       "      <td>१९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     eng  \\\n",
       "0                                                    Go.   \n",
       "1                                                   Run!   \n",
       "2                                                   Run!   \n",
       "3                                                   Run!   \n",
       "4                                                   Run!   \n",
       "...                                                  ...   \n",
       "40746  Just saying you don't like fish because of the...   \n",
       "40747  The Japanese Parliament today officially elect...   \n",
       "40748  Tom tried to sell his old VCR instead of throw...   \n",
       "40749  You can't view Flash content on an iPad. Howev...   \n",
       "40750  In 1969, Roger Miller recorded a song called \"...   \n",
       "\n",
       "                                                     mar  \\\n",
       "0                                                    जा.   \n",
       "1                                                    पळ!   \n",
       "2                                                   धाव!   \n",
       "3                                                   पळा!   \n",
       "4                                                  धावा!   \n",
       "...                                                  ...   \n",
       "40746  हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...   \n",
       "40747  आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...   \n",
       "40748  टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...   \n",
       "40749  आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...   \n",
       "40750  १९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह...   \n",
       "\n",
       "                                                    code  \n",
       "0      CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "1      CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "2      CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "3      CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "4      CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "...                                                  ...  \n",
       "40746  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "40747  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "40748  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "40749  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "40750  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "\n",
       "[40751 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lOVERCASE ALL CHARACTERS\n",
    "import re, string\n",
    "\n",
    "lines.eng= lines.eng.apply(lambda x: x.lower())\n",
    "lines.mar=lines.mar.apply(lambda x: x.lower())\n",
    "\n",
    "#Remove quotes\n",
    "\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.mar=lines.mar.apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "#remove all numbers from text\n",
    "\n",
    "remove_digits = str.maketrans('', '', string.digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.mar = lines.mar.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "#Remove all the special characters\n",
    "exclude = set(string.punctuation) # Set of all specialcharacters\n",
    "\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.mar = lines.mar.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "#Remove extra spaces\n",
    "\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.mar=lines.mar.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.mar=lines.mar.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Below we compute the vocabulary for both English and Marathi. We also compute the vocabulary sizes and the length of maximum sequence for both the languages. Finally we create 4 Python dictionaries (two for each language) to convert a given token into an integer index and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocalulary in English\n",
    "all_eng_words =set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "\n",
    "# Vocabulary of Maratthi\n",
    "all_marathi_words=set()\n",
    "for mar in lines.mar:\n",
    "    for word in mar.split():\n",
    "        if word not in all_marathi_words:\n",
    "            all_marathi_words.add(word)\n",
    "            \n",
    "            \n",
    "# Max Length of source sequence\n",
    "length_list=[]\n",
    "for l in lines.eng:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(length_list)\n",
    "\n",
    "\n",
    "# Max Length of target sequence\n",
    "length_list = []\n",
    "for l in lines.mar:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(length_list)\n",
    "\n",
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_marathi_words))\n",
    "\n",
    "# Calculate Vocab size for both source and target\n",
    "\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_marathi_words)\n",
    "num_decoder_tokens += 1 #for zero padding\n",
    "\n",
    "#Create word to token dictionary for both source and target\n",
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "# Create token to word dictionary for both source and target\n",
    "\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for loading Batches of Data\n",
    "\n",
    "Then we make a 90–10 train and test split and write a Python generator function to load the data in batches as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X_train, y_train, batch_size = 128):\n",
    "    \n",
    "    \"\"\" Generate a batch of data\"\"\"\n",
    "    while True:\n",
    "        for j in range(0, len(X_train), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length, max_length_src), dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] #encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t <len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]]= 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to define the Model to be trained\n",
    "\n",
    "Then we define the model required for training as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "#from keras.layers import Embedding\n",
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout,LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tony'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latent_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-57db3ca23865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#encoder_inputs = Input(shape=(None,))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0menc_emb\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_encoder_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_zero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_inputss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mencoder_lstm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_emb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'latent_dim' is not defined"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "\n",
    "#encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputss)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'hello guys when is   ou r   class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello guys when is ou r class'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\" + \", \" \", word) # removes extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello guys when is   our   clase'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>जा</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "      <td>पळ</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>धाव</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run</td>\n",
       "      <td>पळा</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run</td>\n",
       "      <td>धावा</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40746</th>\n",
       "      <td>just saying you dont like fish because of the ...</td>\n",
       "      <td>हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40747</th>\n",
       "      <td>the japanese parliament today officially elect...</td>\n",
       "      <td>आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40748</th>\n",
       "      <td>tom tried to sell his old vcr instead of throw...</td>\n",
       "      <td>टॉमने त्याचा जुना व्हीसीआर फेकून टाकण्याऐवजी व...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40749</th>\n",
       "      <td>you cant view flash content on an ipad however...</td>\n",
       "      <td>आयपॅडवर फ्लॅश आशय बघता येत नाही पण तुम्ही त्या...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40750</th>\n",
       "      <td>in roger miller recorded a song called you don...</td>\n",
       "      <td>मध्ये रॉजर मिलरने यू डोन्ट वॉन्ट माय लव्ह नावा...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     eng  \\\n",
       "0                                                     go   \n",
       "1                                                    run   \n",
       "2                                                    run   \n",
       "3                                                    run   \n",
       "4                                                    run   \n",
       "...                                                  ...   \n",
       "40746  just saying you dont like fish because of the ...   \n",
       "40747  the japanese parliament today officially elect...   \n",
       "40748  tom tried to sell his old vcr instead of throw...   \n",
       "40749  you cant view flash content on an ipad however...   \n",
       "40750  in roger miller recorded a song called you don...   \n",
       "\n",
       "                                                     mar  \\\n",
       "0                                                     जा   \n",
       "1                                                     पळ   \n",
       "2                                                    धाव   \n",
       "3                                                    पळा   \n",
       "4                                                   धावा   \n",
       "...                                                  ...   \n",
       "40746  हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...   \n",
       "40747  आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...   \n",
       "40748  टॉमने त्याचा जुना व्हीसीआर फेकून टाकण्याऐवजी व...   \n",
       "40749  आयपॅडवर फ्लॅश आशय बघता येत नाही पण तुम्ही त्या...   \n",
       "40750  मध्ये रॉजर मिलरने यू डोन्ट वॉन्ट माय लव्ह नावा...   \n",
       "\n",
       "                                                    code  \n",
       "0      CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "1      CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "2      CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "3      CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "4      CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "...                                                  ...  \n",
       "40746  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "40747  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "40748  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "40749  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "40750  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "\n",
       "[40751 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
